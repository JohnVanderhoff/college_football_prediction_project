{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1\n",
    "In this model in our two-model layer, we start with input the recent historical stats of the teams in a game and predict the stats for the team in their pending matchup. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.linear_model import Ridge\n",
    "pd.options.mode.chained_assignment = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school</th>\n",
       "      <th>school_id</th>\n",
       "      <th>points</th>\n",
       "      <th>fumblesRecovered</th>\n",
       "      <th>rushingTDs</th>\n",
       "      <th>passingTDs</th>\n",
       "      <th>kickReturnYards</th>\n",
       "      <th>kickReturnTDs</th>\n",
       "      <th>kickReturns</th>\n",
       "      <th>kickingPoints</th>\n",
       "      <th>...</th>\n",
       "      <th>opposing_rushingTDs</th>\n",
       "      <th>opposing_points</th>\n",
       "      <th>side</th>\n",
       "      <th>thirdDownConverts</th>\n",
       "      <th>thirdDownAttempts</th>\n",
       "      <th>fourthDownConverts</th>\n",
       "      <th>fourthDownAttempts</th>\n",
       "      <th>completions</th>\n",
       "      <th>passAttempts</th>\n",
       "      <th>passCompletionPercentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Navy</td>\n",
       "      <td>2426</td>\n",
       "      <td>17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>34</td>\n",
       "      <td>A</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UAB</td>\n",
       "      <td>5</td>\n",
       "      <td>48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10</td>\n",
       "      <td>A</td>\n",
       "      <td>9.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UMass</td>\n",
       "      <td>113</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>30</td>\n",
       "      <td>A</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.409091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UCF</td>\n",
       "      <td>2116</td>\n",
       "      <td>24</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26</td>\n",
       "      <td>A</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.545455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Houston</td>\n",
       "      <td>248</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>27</td>\n",
       "      <td>A</td>\n",
       "      <td>4.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    school  school_id  points  fumblesRecovered  rushingTDs  passingTDs  \\\n",
       "0     Navy       2426      17               0.0         2.0         0.0   \n",
       "1      UAB          5      48               1.0         4.0         2.0   \n",
       "2    UMass        113       7               0.0         0.0         1.0   \n",
       "3      UCF       2116      24               1.0         2.0         1.0   \n",
       "4  Houston        248       7               1.0         1.0         0.0   \n",
       "\n",
       "   kickReturnYards  kickReturnTDs  kickReturns  kickingPoints  ...  \\\n",
       "0             64.0            0.0          4.0            5.0  ...   \n",
       "1             64.0            0.0          2.0           12.0  ...   \n",
       "2             95.0            0.0          4.0            1.0  ...   \n",
       "3            142.0            0.0          5.0            6.0  ...   \n",
       "4             89.0            0.0          6.0            1.0  ...   \n",
       "\n",
       "   opposing_rushingTDs  opposing_points  side  thirdDownConverts  \\\n",
       "0                  1.0               34     A                4.0   \n",
       "1                  1.0               10     A                9.0   \n",
       "2                  2.0               30     A                3.0   \n",
       "3                  1.0               26     A                5.0   \n",
       "4                  3.0               27     A                4.0   \n",
       "\n",
       "   thirdDownAttempts  fourthDownConverts  fourthDownAttempts  completions  \\\n",
       "0               12.0                 1.0                 1.0          2.0   \n",
       "1               14.0                 0.0                 0.0         13.0   \n",
       "2               11.0                 1.0                 1.0          9.0   \n",
       "3               13.0                 2.0                 2.0         12.0   \n",
       "4               16.0                 4.0                 4.0         25.0   \n",
       "\n",
       "  passAttempts  passCompletionPercentage  \n",
       "0          4.0                  0.500000  \n",
       "1         20.0                  0.650000  \n",
       "2         22.0                  0.409091  \n",
       "3         22.0                  0.545455  \n",
       "4         50.0                  0.500000  \n",
       "\n",
       "[5 rows x 59 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "games_df = pd.read_csv(\"clean_games_with_opp.csv\", index_col=0)\n",
    "games_df.reset_index(drop=True, inplace=True)\n",
    "games_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping all columns with more than 25 nulls, then dropping the individual rows that have nulls\n",
    "x = games_df.isna().sum().to_dict()\n",
    "column_drop = []\n",
    "\n",
    "for k, v in x.items():\n",
    "    if v > 25 :\n",
    "        column_drop.append(k)\n",
    "\n",
    "# Additionally, these columns are weird formats or already covered by other variables (ie the possession stuff)\n",
    "extend_list = ['completionAttempts','totalPenaltiesYards','possessionTime','possession_minutes','possession_seconds','year','week','school','points','opposing_points']\n",
    "\n",
    "#column_drop.extend(extend_list)\n",
    "column_drop = column_drop + extend_list\n",
    "\n",
    "games_df.drop(columns=column_drop, inplace = True)\n",
    "games_df.dropna(axis = 0, inplace = True)\n",
    "\n",
    "games_df = games_df.select_dtypes(exclude=[\"object\"])\n",
    "\n",
    "games_df = games_df.sort_values(\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['school_id', 'fumblesRecovered', 'rushingTDs', 'passingTDs',\n",
       "       'firstDowns', 'thirdDownEff', 'totalYards', 'netPassingYards',\n",
       "       'yardsPerPass', 'rushingYards', 'rushingAttempts',\n",
       "       'yardsPerRushAttempt', 'turnovers', 'fumblesLost', 'interceptions',\n",
       "       'poss_total_sec', 'id', 'opposing_netPassingYards',\n",
       "       'opposing_yardsPerPass', 'opposing_rushingYards',\n",
       "       'opposing_yardsPerRushAttempt', 'opposing_passingTDs',\n",
       "       'opposing_rushingTDs', 'thirdDownConverts', 'thirdDownAttempts',\n",
       "       'fourthDownConverts', 'fourthDownAttempts', 'completions',\n",
       "       'passAttempts', 'passCompletionPercentage'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "games_df.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We initially set the historical memory equal to 12 games. This is roughly the past seasons-worth of games for an average team. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{2, 2050, 5, 6, 2567, 8, 9, 2569, 2571, 12, 2572, 13, 16, 2065, 2579, 21, 2582, 23, 24, 25, 26, 3101, 30, 2083, 2084, 36, 38, 2598, 41, 43, 47, 48, 2097, 50, 52, 55, 57, 58, 59, 2617, 61, 62, 2110, 2619, 2623, 66, 2115, 2116, 2117, 2628, 68, 70, 2633, 2630, 2635, 2636, 77, 2638, 79, 2127, 2641, 2634, 2643, 84, 2132, 2640, 87, 2649, 2653, 2142, 2655, 96, 97, 98, 99, 93, 103, 107, 113, 2674, 2678, 119, 120, 2681, 2169, 127, 130, 2692, 2181, 135, 2184, 142, 145, 2193, 147, 149, 150, 151, 152, 153, 154, 2711, 2199, 2717, 158, 155, 160, 2210, 164, 166, 167, 2729, 2226, 2229, 2230, 183, 2747, 189, 2751, 193, 194, 195, 2754, 197, 2755, 2247, 2241, 201, 202, 204, 2771, 213, 2261, 218, 221, 222, 227, 228, 2277, 231, 233, 235, 236, 238, 239, 2287, 242, 2803, 245, 2294, 248, 249, 2296, 251, 252, 253, 254, 256, 2305, 258, 259, 2306, 2309, 257, 264, 265, 2320, 275, 276, 277, 278, 2837, 2329, 282, 2335, 290, 2341, 295, 2348, 301, 2197, 302, 304, 2198, 309, 311, 322, 2710, 324, 326, 328, 2377, 331, 333, 2382, 338, 2390, 344, 2393, 349, 2400, 356, 2405, 2916, 2415, 2426, 2428, 2429, 2433, 2439, 2440, 2447, 399, 2449, 2450, 2448, 2453, 2458, 2459, 2460, 2464, 2466, 2627, 2483, 2502, 2504, 2506, 2509, 2000, 2005, 2006, 2010, 2011, 2523, 2016, 2529, 2534, 2535, 2026, 2029, 2542, 2032, 2545, 2546, 2046}\n",
      "245\n"
     ]
    }
   ],
   "source": [
    "teams = set(games_df[\"school_id\"])\n",
    "print(teams)\n",
    "print(len(teams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "for team in teams:\n",
    "    team_df = games_df[games_df[\"school_id\"] == team]\n",
    "    team_df = team_df.sort_values(\"id\")\n",
    "    team_df.drop(columns=[\"id\", \"school_id\"], inplace=True)\n",
    "    team_array = np.array(team_df)\n",
    "    \n",
    "    for i in range(memory, len(team_array)):\n",
    "        X.append(np.hstack(team_array[i-memory:i]))\n",
    "        y.append(team_array[i])\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n",
      "28\n"
     ]
    }
   ],
   "source": [
    "print(len(team_df.keys()))\n",
    "print(len(y[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now split the data into the training and testing sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have the train and test data, we will scale the input to the model. Since the output is stats each working on the same scales as the inputs, we scale the output as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "scaler2 = StandardScaler()\n",
    "scaler2.fit(y_train)\n",
    "y_train_scaled = scaler2.transform(y_train)\n",
    "y_test_scaled = scaler2.transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and testing models\n",
    "We first try some linear models for predicting the stats in the next game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Ridge(alpha=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Ridge</label><div class=\"sk-toggleable__content\"><pre>Ridge(alpha=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "Ridge(alpha=1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge, ElasticNet, Lasso, LinearRegression\n",
    "\n",
    "reg25 = Ridge(alpha=0.25)\n",
    "reg25.fit(X_train_scaled, y_train_scaled)\n",
    "\n",
    "reg50 = Ridge(alpha=0.5)\n",
    "reg50.fit(X_train_scaled, y_train_scaled)\n",
    "\n",
    "reg100 = Ridge(alpha=1)\n",
    "reg100.fit(X_train_scaled, y_train_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now make predictions with the ridge models on the test set and compute the mean squared error. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha: MSE are: \n",
      " 0.25:0.9289504736159343 \n",
      " 0.50:0.9289502575653117 \n",
      " 1.00:0.9289266963929623\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "pred_scores25 = reg25.predict(X_test_scaled)\n",
    "pred_scores50 = reg50.predict(X_test_scaled)\n",
    "pred_scores100 = reg100.predict(X_test_scaled)\n",
    "\n",
    "print(f\"alpha: MSE are: \\n 0.25:{mean_squared_error(pred_scores25, y_test_scaled)} \\n 0.50:{mean_squared_error(pred_scores50, y_test_scaled)} \\n 1.00:{mean_squared_error(pred_scores100, y_test_scaled)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE are \n",
      " Lasso:0.9948268539848032\n",
      " ElasticNet:0.9948268539848032\n"
     ]
    }
   ],
   "source": [
    "lasso = Lasso(alpha=1)\n",
    "lasso.fit(X_train_scaled, y_train_scaled)\n",
    "\n",
    "ela_net = ElasticNet(alpha=1)\n",
    "ela_net.fit(X_train_scaled, y_train_scaled)\n",
    "\n",
    "print(f\"MSE are \\n Lasso:{mean_squared_error(lasso.predict(X_test_scaled), y_test_scaled)}\\n ElasticNet:{mean_squared_error(ela_net.predict(X_test_scaled), y_test_scaled)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous modelling attempts, we predicted the stats for a given team based only on that team's history. Now we will try to look at predicting stats for a given game based on the combined histories of the two teams playing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "teams_dict = {}\n",
    "for team in teams:\n",
    "    temp_df = games_df[games_df[\"school_id\"] == team].sort_values(\"id\")\n",
    "    #temp_df.reset_index(inplace=True)\n",
    "    teams_dict[team] = temp_df.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on team 2\n",
      "on team 2050\n",
      "on team 5\n",
      "on team 6\n",
      "on team 2567\n",
      "on team 8\n",
      "on team 9\n",
      "on team 2569\n",
      "on team 2571\n",
      "on team 12\n",
      "on team 2572\n",
      "on team 13\n",
      "on team 16\n",
      "on team 2065\n",
      "on team 2579\n",
      "on team 21\n",
      "on team 2582\n",
      "on team 23\n",
      "on team 24\n",
      "on team 25\n",
      "on team 26\n",
      "on team 3101\n",
      "on team 30\n",
      "on team 2083\n",
      "on team 2084\n",
      "on team 36\n",
      "on team 38\n",
      "on team 2598\n",
      "on team 41\n",
      "on team 43\n",
      "on team 47\n",
      "on team 48\n",
      "on team 2097\n",
      "on team 50\n",
      "on team 52\n",
      "on team 55\n",
      "on team 57\n",
      "on team 58\n",
      "on team 59\n",
      "on team 2617\n",
      "on team 61\n",
      "on team 62\n",
      "on team 2110\n",
      "on team 2619\n",
      "on team 2623\n",
      "on team 66\n",
      "on team 2115\n",
      "on team 2116\n",
      "on team 2117\n",
      "on team 2628\n",
      "on team 68\n",
      "on team 70\n",
      "on team 2633\n",
      "on team 2630\n",
      "on team 2635\n",
      "on team 2636\n",
      "on team 77\n",
      "on team 2638\n",
      "on team 79\n",
      "on team 2127\n",
      "on team 2641\n",
      "on team 2634\n",
      "on team 2643\n",
      "on team 84\n",
      "on team 2132\n",
      "on team 2640\n",
      "on team 87\n",
      "on team 2649\n",
      "on team 2653\n",
      "on team 2142\n",
      "on team 2655\n",
      "on team 96\n",
      "on team 97\n",
      "on team 98\n",
      "on team 99\n",
      "on team 93\n",
      "on team 103\n",
      "on team 107\n",
      "on team 113\n",
      "on team 2674\n",
      "on team 2678\n",
      "on team 119\n",
      "on team 120\n",
      "on team 2681\n",
      "on team 2169\n",
      "on team 127\n",
      "on team 130\n",
      "on team 2692\n",
      "on team 2181\n",
      "on team 135\n",
      "on team 2184\n",
      "on team 142\n",
      "on team 145\n",
      "on team 2193\n",
      "on team 147\n",
      "on team 149\n",
      "on team 150\n",
      "on team 151\n",
      "on team 152\n",
      "on team 153\n",
      "on team 154\n",
      "on team 2711\n",
      "on team 2199\n",
      "on team 2717\n",
      "on team 158\n",
      "on team 155\n",
      "on team 160\n",
      "on team 2210\n",
      "on team 164\n",
      "on team 166\n",
      "on team 167\n",
      "on team 2729\n",
      "on team 2226\n",
      "on team 2229\n",
      "on team 2230\n",
      "on team 183\n",
      "on team 2747\n",
      "on team 189\n",
      "on team 2751\n",
      "on team 193\n",
      "on team 194\n",
      "on team 195\n",
      "on team 2754\n",
      "on team 197\n",
      "on team 2755\n",
      "on team 2247\n",
      "on team 2241\n",
      "on team 201\n",
      "on team 202\n",
      "on team 204\n",
      "on team 2771\n",
      "on team 213\n",
      "on team 2261\n",
      "on team 218\n",
      "on team 221\n",
      "on team 222\n",
      "on team 227\n",
      "on team 228\n",
      "on team 2277\n",
      "on team 231\n",
      "on team 233\n",
      "on team 235\n",
      "on team 236\n",
      "on team 238\n",
      "on team 239\n",
      "on team 2287\n",
      "on team 242\n",
      "on team 2803\n",
      "on team 245\n",
      "on team 2294\n",
      "on team 248\n",
      "on team 249\n",
      "on team 2296\n",
      "on team 251\n",
      "on team 252\n",
      "on team 253\n",
      "on team 254\n",
      "on team 256\n",
      "on team 2305\n",
      "on team 258\n",
      "on team 259\n",
      "on team 2306\n",
      "on team 2309\n",
      "on team 257\n",
      "on team 264\n",
      "on team 265\n",
      "on team 2320\n",
      "on team 275\n",
      "on team 276\n",
      "on team 277\n",
      "on team 278\n",
      "on team 2837\n",
      "on team 2329\n",
      "on team 282\n",
      "on team 2335\n",
      "on team 290\n",
      "on team 2341\n",
      "on team 295\n",
      "on team 2348\n",
      "on team 301\n",
      "on team 2197\n",
      "on team 302\n",
      "on team 304\n",
      "on team 2198\n",
      "on team 309\n",
      "on team 311\n",
      "on team 322\n",
      "on team 2710\n",
      "on team 324\n",
      "on team 326\n",
      "on team 328\n",
      "on team 2377\n",
      "on team 331\n",
      "on team 333\n",
      "on team 2382\n",
      "on team 338\n",
      "on team 2390\n",
      "on team 344\n",
      "on team 2393\n",
      "on team 349\n",
      "on team 2400\n",
      "on team 356\n",
      "on team 2405\n",
      "on team 2916\n",
      "on team 2415\n",
      "on team 2426\n",
      "on team 2428\n",
      "on team 2429\n",
      "on team 2433\n",
      "on team 2439\n",
      "on team 2440\n",
      "on team 2447\n",
      "on team 399\n",
      "on team 2449\n",
      "on team 2450\n",
      "on team 2448\n",
      "on team 2453\n",
      "on team 2458\n",
      "on team 2459\n",
      "on team 2460\n",
      "on team 2464\n",
      "on team 2466\n",
      "on team 2627\n",
      "on team 2483\n",
      "on team 2502\n",
      "on team 2504\n",
      "on team 2506\n",
      "on team 2509\n",
      "on team 2000\n",
      "on team 2005\n",
      "on team 2006\n",
      "on team 2010\n",
      "on team 2011\n",
      "on team 2523\n",
      "on team 2016\n",
      "on team 2529\n",
      "on team 2534\n",
      "on team 2535\n",
      "on team 2026\n",
      "on team 2029\n",
      "on team 2542\n",
      "on team 2032\n",
      "on team 2545\n",
      "on team 2546\n",
      "on team 2046\n"
     ]
    }
   ],
   "source": [
    "X2 = []\n",
    "y2 = []\n",
    "for team in teams:\n",
    "    team1_df = teams_dict[team]\n",
    "    print(f\"on team {team}\")\n",
    "    \n",
    "    # loop over all possible games for a given team with enough prior games\n",
    "    for i in range(memory, len(team1_df)):\n",
    "        # find the two teams participating in the game\n",
    "        game_id = team1_df.loc[i][\"id\"]\n",
    "        both_teams_ids = games_df[games_df[\"id\"] == game_id][\"school_id\"]\n",
    "        both_teams_ids = list(both_teams_ids)\n",
    "\n",
    "        # throw out some odd cases where  there was only data for one of the teams in a given game\n",
    "        if len(both_teams_ids) != 2:\n",
    "            continue\n",
    "        #print(f\"both teams are {both_teams_ids}\")\n",
    " \n",
    "        # extract the dataframes for the two teams, find which game it was for them\n",
    "        t1_df = teams_dict[both_teams_ids[0]]#.loc[i-memory:i+1]\n",
    "        t2_df = teams_dict[both_teams_ids[1]]#.loc[i-memory:i+1]\n",
    "\n",
    "        t1_gamen = np.where(t1_df[\"id\"] == game_id)[0][0]\n",
    "        t2_gamen = np.where(t2_df[\"id\"] == game_id)[0][0]\n",
    "\n",
    "        # check to make sure that both teams have enough games in the past\n",
    "        if t1_gamen < memory or t2_gamen < memory:\n",
    "            continue\n",
    "        \n",
    "        # extract the games in recent history, dropping columns that don't go into the data\n",
    "        t1_df = t1_df.loc[t1_gamen-memory:t1_gamen]#+1]\n",
    "        t2_df = t2_df.loc[t2_gamen-memory:t2_gamen]#+1]\n",
    "        t1_df.drop(columns=[\"id\", \"school_id\"], inplace=True)\n",
    "        t2_df.drop(columns=[\"id\", \"school_id\"], inplace=True)\n",
    "\n",
    "        t1_array = np.array(t1_df)\n",
    "        t2_array = np.array(t2_df)\n",
    "\n",
    "        # break the arrays into past games and current game to go into training and test set\n",
    "        t1_past = t1_array[0:-1]\n",
    "        t1_present = t1_array[-1]\n",
    "        t2_past = t2_array[0:-1]\n",
    "        t2_present = t2_array[-1]\n",
    "\n",
    "\n",
    "        X2.append(np.hstack([t1_past, t2_past]))\n",
    "        y2.append(np.hstack([t1_present, t2_present]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2_flat = []\n",
    "for i in range(len(X2)):\n",
    "    X2_flat.append(X2[i].reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12742, 672) (12742, 56)\n"
     ]
    }
   ],
   "source": [
    "X2_flat = np.array(X2_flat)\n",
    "y2 = np.array(y2)\n",
    "print(X2_flat.shape, y2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we scale the data, split it into train and test sets, and then train and test various models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X2_flat, y2, test_size=0.25, random_state=42)\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X2_train)\n",
    "X2_train_scaled = scaler.transform(X2_train)\n",
    "X2_test_scaled = scaler.transform(X2_test)\n",
    "\n",
    "scaler2 = StandardScaler()\n",
    "scaler2.fit(y2_train)\n",
    "y2_train_scaled = scaler2.transform(y2_train)\n",
    "y2_test_scaled = scaler2.transform(y2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Ridge(alpha=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Ridge</label><div class=\"sk-toggleable__content\"><pre>Ridge(alpha=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "Ridge(alpha=1)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg25 = Ridge(alpha=0.25)\n",
    "reg25.fit(X2_train_scaled, y2_train_scaled)\n",
    "\n",
    "reg50 = Ridge(alpha=0.5)\n",
    "reg50.fit(X2_train_scaled, y2_train_scaled)\n",
    "\n",
    "reg100 = Ridge(alpha=1)\n",
    "reg100.fit(X2_train_scaled, y2_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha: MSE are: \n",
      " 0.25:0.8558815223889026 \n",
      " 0.50:0.8559164936772383 \n",
      " 1.00:0.855879334615943\n"
     ]
    }
   ],
   "source": [
    "pred_scores25 = reg25.predict(X2_test_scaled)\n",
    "pred_scores50 = reg50.predict(X2_test_scaled)\n",
    "pred_scores100 = reg100.predict(X2_test_scaled)\n",
    "\n",
    "print(f\"alpha: MSE are: \\n 0.25:{mean_squared_error(pred_scores25, y2_test_scaled)} \\n 0.50:{mean_squared_error(pred_scores50, y2_test_scaled)} \\n 1.00:{mean_squared_error(pred_scores100, y2_test_scaled)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the performance is improved by considering the historical data of both teams, not just each team independently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_science_bootcamp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
